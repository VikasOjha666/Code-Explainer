{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w53mF5x-5DS9",
        "outputId": "c457b26b-e02e-40b2-91ac-6675d8d57b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 30 15:51:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    22W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64-P74IY2__H",
        "outputId": "c02fbab1-ba6c-4708-d919-32ab32ac5c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dl2YDOFs47flOv7-QxUeG-YPQMMSEWRE&confirm=t\n",
            "To: /content/combined_dataset_code.zip\n",
            "\r  0% 0.00/1.50M [00:00<?, ?B/s]\r100% 1.50M/1.50M [00:00<00:00, 142MB/s]\n"
          ]
        }
      ],
      "source": [
        "!python3 -m gdown.cli \"https://drive.google.com/uc?id=1dl2YDOFs47flOv7-QxUeG-YPQMMSEWRE&confirm=t\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/combined_dataset_code.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQBMxv-93f7S",
        "outputId": "a7da608d-dd31-409e-9cc0-cfb075413d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/combined_dataset_code.zip\n",
            "   creating: combined_dataset/\n",
            "  inflating: combined_dataset/data-00000-of-00001.arrow  \n",
            "  inflating: combined_dataset/dataset_info.json  \n",
            "  inflating: combined_dataset/state.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets huggingface transformers==4.31"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qlIxJFo3oTi",
        "outputId": "6d367174-9ae3-426c-9a0b-e2a594d2d1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: huggingface in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Collecting transformers==4.31\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk,concatenate_datasets\n",
        "import os\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "SDAq8Q9R30AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge the datasets.\n",
        "concat_data=load_from_disk(\"/content/combined_dataset\")\n"
      ],
      "metadata": {
        "id": "ciZt6rWA4Nut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the above data into completion format.\n",
        "source_texts=concat_data['source_texts']\n",
        "target_texts=concat_data['target_texts']\n",
        "\n",
        "auto_comp_list=[]\n",
        "\n",
        "for i in range(len(source_texts)):\n",
        "  source_txt=source_texts[i]\n",
        "  target_txt=target_texts[i]\n",
        "  auto_txt=f'### Human: {source_txt}.### Assistant: {target_txt}<EOS>'\n",
        "\n",
        "  auto_comp_list.append(auto_txt)\n",
        "\n",
        "data_dict={\"text\":auto_comp_list}\n",
        "autodataset=Dataset.from_dict(data_dict)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dk57ngdzAxST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dM0NE11vyxPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGbPT7BHyyZ8",
        "outputId": "808df9bf-f1ff-4552-a6c6-f71c26aeda6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m194.6/244.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "E3H1S-ZOyzRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model that you want to train from the Hugging Face hub\n",
        "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "\n",
        "\n",
        "# The instruction dataset to use\n",
        "dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
        "\n",
        "# Fine-tuned model name\n",
        "new_model = \"llama-2-7b-codeexplainer\"\n",
        "\n",
        "################################################################################\n",
        "# QLoRA parameters\n",
        "################################################################################\n",
        "\n",
        "# LoRA attention dimension\n",
        "lora_r = 64\n",
        "\n",
        "# Alpha parameter for LoRA scaling\n",
        "lora_alpha = 16\n",
        "\n",
        "# Dropout probability for LoRA layers\n",
        "lora_dropout = 0.1\n",
        "\n",
        "################################################################################\n",
        "# bitsandbytes parameters\n",
        "################################################################################\n",
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "use_nested_quant = False\n",
        "\n",
        "################################################################################\n",
        "# TrainingArguments parameters\n",
        "################################################################################\n",
        "\n",
        "# Output directory where the model predictions and checkpoints will be stored\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# Number of training epochs\n",
        "num_train_epochs = 1\n",
        "\n",
        "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "\n",
        "# Batch size per GPU for training\n",
        "per_device_train_batch_size = 4\n",
        "\n",
        "# Batch size per GPU for evaluation\n",
        "per_device_eval_batch_size = 4\n",
        "\n",
        "# Number of update steps to accumulate the gradients for\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "gradient_checkpointing = True\n",
        "\n",
        "# Maximum gradient normal (gradient clipping)\n",
        "max_grad_norm = 0.3\n",
        "\n",
        "# Initial learning rate (AdamW optimizer)\n",
        "learning_rate = 2e-4\n",
        "\n",
        "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "weight_decay = 0.001\n",
        "\n",
        "# Optimizer to use\n",
        "optim = \"paged_adamw_32bit\"\n",
        "\n",
        "# Learning rate schedule\n",
        "lr_scheduler_type = \"cosine\"\n",
        "\n",
        "# Number of training steps (overrides num_train_epochs)\n",
        "max_steps = 3000\n",
        "\n",
        "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "warmup_ratio = 0.03\n",
        "\n",
        "# Group sequences into batches with same length\n",
        "# Saves memory and speeds up training considerably\n",
        "group_by_length = True\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 25\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 25\n",
        "\n",
        "################################################################################\n",
        "# SFT parameters\n",
        "################################################################################\n",
        "\n",
        "# Maximum sequence length to use\n",
        "max_seq_length = None\n",
        "\n",
        "# Pack multiple short examples in the same input sequence to increase efficiency\n",
        "packing = False\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}"
      ],
      "metadata": {
        "id": "a57XOfhAy3e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (you can process it here)\n",
        "\n",
        "\n",
        "# Load tokenizer and model with QLoRA configuration\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "# Check GPU compatibility with bfloat16\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_7b, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
        "\n",
        "# Load LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\"\n",
        ")\n",
        "\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=autodataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save trained model\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hOSbNeqay-dF",
        "outputId": "7eb423c5-7825-4de8-b58b-b4cd8aa6928f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 2:29:39, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.046800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.057200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.530500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.645900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.353900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.573900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.330400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.541800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.291200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.550700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.311900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.515600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.514200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.273300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.507000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>0.285800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.532800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>0.270800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.522500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>0.284300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.497900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>0.317500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.496500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>0.260300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.516100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.267900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.463900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>0.281400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.445600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>0.295600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.504600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>0.275600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.474100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>0.247000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.498400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>0.262600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.457600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>0.356000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.303400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>0.398600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.291000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>0.408700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.273000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>0.398300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.272900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>0.394500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.301100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.376400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>0.414000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.396400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.296100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>0.381700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.260700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>0.392300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.323200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>0.403900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.252600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>0.367800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.254700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>0.375700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.299300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>0.375800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.255000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>0.373500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.281800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>0.356400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.285900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>0.356600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.287200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>0.372100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.284500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>0.390900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.287900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>0.380000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.290300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>0.310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.317000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>0.310600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.328500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>0.300800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.305200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>0.324500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.303800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>0.279400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.276100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>0.326800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.270200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>0.291200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.304400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>0.294300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.288200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>0.248600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.300500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>0.292000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.302100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.317300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.303400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>0.296800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.305100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2575</td>\n",
              "      <td>0.278700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.301900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2625</td>\n",
              "      <td>0.279300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.287400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2675</td>\n",
              "      <td>0.279000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2725</td>\n",
              "      <td>0.255200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.278500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2775</td>\n",
              "      <td>0.302600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.288800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2825</td>\n",
              "      <td>0.332300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.286000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2875</td>\n",
              "      <td>0.321000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.338700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2925</td>\n",
              "      <td>0.262700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.368600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2975</td>\n",
              "      <td>0.250700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.332600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'arr1 = np.array([1, 2, 3, 4, 5])\\n arr2 = arr1 + 2\\n arr3 = arr1 * 3\\n matrix = np.array([[1, 2, 3], [4, 5, 6]])\\n sum_column = np.sum(matrix, axis=0)\\n product_row = np.product(matrix, axis=1) \\n print(\"Sum of columns:\", sum_column)\\n print(\"Product of rows:\", product_row)'\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
        "result = pipe(f\"### Human: {prompt}.### Assistant:\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2TbgmgSBzHH",
        "outputId": "36602310-705c-4622-9933-8c1f56eccc71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Human: arr1 = np.array([1, 2, 3, 4, 5])\n",
            " arr2 = arr1 + 2\n",
            " arr3 = arr1 * 3\n",
            " matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
            " sum_column = np.sum(matrix, axis=0)\n",
            " product_row = np.product(matrix, axis=1) \n",
            " print(\"Sum of columns:\", sum_column)\n",
            " print(\"Product of rows:\", product_row).### Assistant: The code you provided demonstrates how to perform various operations on NumPy arrays. Here's a breakdown of what the code does:\n",
            "```python<button class=\"flex ml-auto gizmo:ml-0 gap-2 items-center\"><svg stroke=\"currentColor\" fill=\"none\" stroke-width=\"2\" viewBox=\"0 0 24 24\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"icon-sm\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2\"></path><rect x=\"8\" y=\"2\" width=\"8\" height=\"4\" rx=\"1\" ry=\"1\"></rect></svg>Copy code</button>\n",
            "import numpy as np\n",
            "\n",
            "# Create an array\n",
            "arr1 = np.array([1, 2, 3, 4, 5])\n",
            "\n",
            "# Add 2 to each element\n",
            "arr2 = arr1 + 2\n",
            "\n",
            "# Multiply each element by 3\n",
            "arr3 = arr1 * 3\n",
            "\n",
            "# Create a 2x3 matrix\n",
            "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
            "\n",
            "# Sum of columns\n",
            "sum_column = np.sum(matrix, axis=0)\n",
            "\n",
            "# Product of rows\n",
            "product_row = np.product(matrix, axis=1)\n",
            "\n",
            "# Print the results\n",
            "print(\"Sum of columns:\", sum_column)\n",
            "print(\"Product of rows:\", product_row)\n",
            "\n",
            "```\n",
            "\n",
            "- `np.sum(matrix, axis=0)` calculates the sum of columns in the `matrix` array.\n",
            "- `np.product(matrix, axis=1)` calculates the product of rows in the `matrix` array.\n",
            "\n",
            "The output will be the sums of columns and the products of rows in the specified arrays.\n",
            "\n",
            "\n",
            "\n",
            "------------------<EOS>\n",
            "Important: If you have any questions or need further assistance, please feel free to ask.\n",
            "\n",
            "\n",
            "\n",
            "------------------<EOS>\n",
            "import numpy as np\n",
            "\n",
            "# Create an array\n",
            "arr1 = np.array([1, 2, 3, 4, 5])\n",
            "\n",
            "# Add 2 to each element\n",
            "arr2 = arr1 + 2\n",
            "\n",
            "# Multiply each element by 3\n",
            "arr3 = arr1 * 3\n",
            "\n",
            "# Create a 2x3 matrix\n",
            "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
            "\n",
            "# Sum of columns\n",
            "sum_column = np.sum(matrix, axis=0)\n",
            "\n",
            "# Product of rows\n",
            "product_row = np.product(matrix, axis=1)\n",
            "\n",
            "# Print the results\n",
            "print(\"Sum of columns:\", sum_column)\n",
            "print(\"Product of rows:\", product_row)\n",
            "\n",
            "```\n",
            "\n",
            "- `np.sum(matrix, axis=0)` calculates the sum of columns in the `matrix` array.\n",
            "- `np.product(matrix, axis=1)` calculates the product of rows in the `matrix` array.\n",
            "\n",
            "The output will be the sums of columns and the products of rows in the specified arrays.\n",
            "\n",
            "\n",
            "\n",
            "------------------<EOS>\n",
            "\n",
            "\n",
            "\n",
            "------------------<EOS>\n",
            "import numpy as np\n",
            "\n",
            "# Create an array\n",
            "arr1 = np.array([1, 2, 3, 4, 5])\n",
            "\n",
            "# Add 2 to each element\n",
            "arr2 = arr1 + 2\n",
            "\n",
            "# Multiply each element by 3\n",
            "arr3 = arr1 * 3\n",
            "\n",
            "# Create a 2x3 matrix\n",
            "matrix = np\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.rclone.org/v1.61.1/rclone-v1.61.1-linux-amd64.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhMGJ_0Oe8-H",
        "outputId": "9dd61650-74e6-45a1-a049-e6f76a5d97be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-30 18:27:10--  https://downloads.rclone.org/v1.61.1/rclone-v1.61.1-linux-amd64.deb\n",
            "Resolving downloads.rclone.org (downloads.rclone.org)... 95.217.6.16, 2a01:4f9:c012:7154::1\n",
            "Connecting to downloads.rclone.org (downloads.rclone.org)|95.217.6.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18551554 (18M) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘rclone-v1.61.1-linux-amd64.deb’\n",
            "\n",
            "rclone-v1.61.1-linu 100%[===================>]  17.69M  49.4MB/s    in 0.4s    \n",
            "\n",
            "2023-11-30 18:27:10 (49.4 MB/s) - ‘rclone-v1.61.1-linux-amd64.deb’ saved [18551554/18551554]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo dpkg -i rclone-v1.61.1-linux-amd64.deb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rvvuc8nfDTc",
        "outputId": "12b5fcff-bf2c-4eb3-bd14-65873e4711b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package rclone.\n",
            "(Reading database ... 120882 files and directories currently installed.)\n",
            "Preparing to unpack rclone-v1.61.1-linux-amd64.deb ...\n",
            "Unpacking rclone (1.61.1) ...\n",
            "Setting up rclone (1.61.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rclone config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOkHWrCEfJGZ",
        "outputId": "ba7d4a05-556f-4e79-8f52-094c12fff969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023/11/30 18:28:14 NOTICE: Config file \"/root/.config/rclone/rclone.conf\" not found - using defaults\n",
            "No remotes found, make a new one?\n",
            "n) New remote\n",
            "s) Set configuration password\n",
            "q) Quit config\n",
            "n/s/q> n\n",
            "\n",
            "Enter name for new remote.\n",
            "name> onedrive\n",
            "\n",
            "Option Storage.\n",
            "Type of storage to configure.\n",
            "Choose a number from below, or type in your own value.\n",
            "\u001b[91m 1 / 1Fichier\n",
            "   \\ (fichier)\n",
            "\u001b[0m\u001b[92m 2 / Akamai NetStorage\n",
            "   \\ (netstorage)\n",
            "\u001b[0m\u001b[91m 3 / Alias for an existing remote\n",
            "   \\ (alias)\n",
            "\u001b[0m\u001b[92m 4 / Amazon Drive\n",
            "   \\ (amazon cloud drive)\n",
            "\u001b[0m\u001b[91m 5 / Amazon S3 Compliant Storage Providers including AWS, Alibaba, Ceph, China Mobile, Cloudflare, ArvanCloud, DigitalOcean, Dreamhost, Huawei OBS, IBM COS, IDrive e2, IONOS Cloud, Liara, Lyve Cloud, Minio, Netease, RackCorp, Scaleway, SeaweedFS, StackPath, Storj, Tencent COS, Qiniu and Wasabi\n",
            "   \\ (s3)\n",
            "\u001b[0m\u001b[92m 6 / Backblaze B2\n",
            "   \\ (b2)\n",
            "\u001b[0m\u001b[91m 7 / Better checksums for other remotes\n",
            "   \\ (hasher)\n",
            "\u001b[0m\u001b[92m 8 / Box\n",
            "   \\ (box)\n",
            "\u001b[0m\u001b[91m 9 / Cache a remote\n",
            "   \\ (cache)\n",
            "\u001b[0m\u001b[92m10 / Citrix Sharefile\n",
            "   \\ (sharefile)\n",
            "\u001b[0m\u001b[91m11 / Combine several remotes into one\n",
            "   \\ (combine)\n",
            "\u001b[0m\u001b[92m12 / Compress a remote\n",
            "   \\ (compress)\n",
            "\u001b[0m\u001b[91m13 / Dropbox\n",
            "   \\ (dropbox)\n",
            "\u001b[0m\u001b[92m14 / Encrypt/Decrypt a remote\n",
            "   \\ (crypt)\n",
            "\u001b[0m\u001b[91m15 / Enterprise File Fabric\n",
            "   \\ (filefabric)\n",
            "\u001b[0m\u001b[92m16 / FTP\n",
            "   \\ (ftp)\n",
            "\u001b[0m\u001b[91m17 / Google Cloud Storage (this is not Google Drive)\n",
            "   \\ (google cloud storage)\n",
            "\u001b[0m\u001b[92m18 / Google Drive\n",
            "   \\ (drive)\n",
            "\u001b[0m\u001b[91m19 / Google Photos\n",
            "   \\ (google photos)\n",
            "\u001b[0m\u001b[92m20 / HTTP\n",
            "   \\ (http)\n",
            "\u001b[0m\u001b[91m21 / Hadoop distributed file system\n",
            "   \\ (hdfs)\n",
            "\u001b[0m\u001b[92m22 / HiDrive\n",
            "   \\ (hidrive)\n",
            "\u001b[0m\u001b[91m23 / In memory object storage system.\n",
            "   \\ (memory)\n",
            "\u001b[0m\u001b[92m24 / Internet Archive\n",
            "   \\ (internetarchive)\n",
            "\u001b[0m\u001b[91m25 / Jottacloud\n",
            "   \\ (jottacloud)\n",
            "\u001b[0m\u001b[92m26 / Koofr, Digi Storage and other Koofr-compatible storage providers\n",
            "   \\ (koofr)\n",
            "\u001b[0m\u001b[91m27 / Local Disk\n",
            "   \\ (local)\n",
            "\u001b[0m\u001b[92m28 / Mail.ru Cloud\n",
            "   \\ (mailru)\n",
            "\u001b[0m\u001b[91m29 / Mega\n",
            "   \\ (mega)\n",
            "\u001b[0m\u001b[92m30 / Microsoft Azure Blob Storage\n",
            "   \\ (azureblob)\n",
            "\u001b[0m\u001b[91m31 / Microsoft OneDrive\n",
            "   \\ (onedrive)\n",
            "\u001b[0m\u001b[92m32 / OpenDrive\n",
            "   \\ (opendrive)\n",
            "\u001b[0m\u001b[91m33 / OpenStack Swift (Rackspace Cloud Files, Memset Memstore, OVH)\n",
            "   \\ (swift)\n",
            "\u001b[0m\u001b[92m34 / Oracle Cloud Infrastructure Object Storage\n",
            "   \\ (oracleobjectstorage)\n",
            "\u001b[0m\u001b[91m35 / Pcloud\n",
            "   \\ (pcloud)\n",
            "\u001b[0m\u001b[92m36 / Put.io\n",
            "   \\ (putio)\n",
            "\u001b[0m\u001b[91m37 / QingCloud Object Storage\n",
            "   \\ (qingstor)\n",
            "\u001b[0m\u001b[92m38 / SMB / CIFS\n",
            "   \\ (smb)\n",
            "\u001b[0m\u001b[91m39 / SSH/SFTP\n",
            "   \\ (sftp)\n",
            "\u001b[0m\u001b[92m40 / Sia Decentralized Cloud\n",
            "   \\ (sia)\n",
            "\u001b[0m\u001b[91m41 / Storj Decentralized Cloud Storage\n",
            "   \\ (storj)\n",
            "\u001b[0m\u001b[92m42 / Sugarsync\n",
            "   \\ (sugarsync)\n",
            "\u001b[0m\u001b[91m43 / Transparently chunk/split large files\n",
            "   \\ (chunker)\n",
            "\u001b[0m\u001b[92m44 / Union merges the contents of several upstream fs\n",
            "   \\ (union)\n",
            "\u001b[0m\u001b[91m45 / Uptobox\n",
            "   \\ (uptobox)\n",
            "\u001b[0m\u001b[92m46 / WebDAV\n",
            "   \\ (webdav)\n",
            "\u001b[0m\u001b[91m47 / Yandex Disk\n",
            "   \\ (yandex)\n",
            "\u001b[0m\u001b[92m48 / Zoho\n",
            "   \\ (zoho)\n",
            "\u001b[0m\u001b[91m49 / premiumize.me\n",
            "   \\ (premiumizeme)\n",
            "\u001b[0m\u001b[92m50 / seafile\n",
            "   \\ (seafile)\n",
            "\u001b[0mStorage> 31\n",
            "\n",
            "Option client_id.\n",
            "OAuth Client Id.\n",
            "Leave blank normally.\n",
            "Enter a value. Press Enter to leave empty.\n",
            "client_id> \n",
            "\n",
            "Option client_secret.\n",
            "OAuth Client Secret.\n",
            "Leave blank normally.\n",
            "Enter a value. Press Enter to leave empty.\n",
            "client_secret> \n",
            "\n",
            "Option region.\n",
            "Choose national cloud region for OneDrive.\n",
            "Choose a number from below, or type in your own string value.\n",
            "Press Enter for the default (global).\n",
            "\u001b[91m 1 / Microsoft Cloud Global\n",
            "   \\ (global)\n",
            "\u001b[0m\u001b[92m 2 / Microsoft Cloud for US Government\n",
            "   \\ (us)\n",
            "\u001b[0m\u001b[91m 3 / Microsoft Cloud Germany\n",
            "   \\ (de)\n",
            "\u001b[0m\u001b[92m 4 / Azure and Office 365 operated by Vnet Group in China\n",
            "   \\ (cn)\n",
            "\u001b[0mregion> 1\n",
            "\n",
            "Edit advanced config?\n",
            "y) Yes\n",
            "n) No (default)\n",
            "y/n> n\n",
            "\n",
            "Use web browser to automatically authenticate rclone with remote?\n",
            " * Say Y if the machine running rclone has a web browser you can use\n",
            " * Say N if running rclone on a (remote) machine without web browser access\n",
            "If not sure try Y. If Y failed, try N.\n",
            "\n",
            "y) Yes (default)\n",
            "n) No\n",
            "y/n> n\n",
            "\n",
            "Option config_token.\n",
            "For this to work, you will need rclone available on a machine that has\n",
            "a web browser available.\n",
            "For more help and alternate methods see: https://rclone.org/remote_setup/\n",
            "Execute the following on the machine with the web browser (same rclone\n",
            "version recommended):\n",
            "\trclone authorize \"onedrive\"\n",
            "Then paste the result.\n",
            "Enter a value.\n",
            "config_token> {\"access_token\":\"EwB4A8l6BAAUAOyDv0l6PcCVu89kmzvqZmkWABkAAYViudTwPAMeRPijG8DE4UrtfS8WQZTiG0YOyjraZfoPaPuO0bCe8ClndHPMUgcX1tzy1hwi4Smhg2QeiM3GrbB+XlNXzqv+koTMLFBQUWdcKvpNQtaIVDmylB3obpL676Ky13PGuPlDGotkZZ5RvM3lfEWJirvczMeiC/hOD/e/jL1sJ5Mnj1fIPNazZhiVBKYM7VmLhK+oogBsLZulTprMZeHzhGjHSMNOXNu2IpnrYdJootshVcqadZfwN4VtQVUoejaLf3AKT5q6zPvTru1xSaujIqwXjaRN6bKErh9i2sQV2F7iRfuDcYJ3jqrTFBmukRmg3mO1tLJVPDKWFn0DZgAACGUSmZu0AEreSALimt6peNLvZFDjwx5e2Sd2nDNl/qEPZR4BgIFfdiAS6jbKdkwLl2SyL9dgx0dMEUxg8OVG4eB54mjaM9Z44ETxu9Tydf78jY5j7vZct7coYDdjyOQiTIDbPHaNYIQnFSjNzfx6EUsPh55bLi0wHy3y48bBrDAfZCMrU3TZxAPBSF9FlF9yFjzcqSxqAFkWXRFVEZ54riTPYn4JRLjb/9dfUfbIuFiPZI5xC3P6piDny2vrv4bozTUAxpt1mllsXUpLRfOWGY2NThHpxqkdhIuo7CSfIWHG6vdIKK1hkh+Pd+0TVWSEXUP7ETvrn27xQG1GMNzYNvuvLBvosaDYrinPpNpOZi6ooMM8FRe90pNDeSxkexOPhXF/fHn6S0017B/Gk8t7ht4+ZPBxyVvZDR9HKidLhRHtUC+moXeK+ThQRmDcwsBbhvEBhcS1JWA0RO6GY8F0OWEpHJnSVbyuiXMFYVrWJc/ua1j6BIpXVDZ1KEPiCm6/HfeTBoGDT/+J8e4VfOvb8i8lcT5zntMVF7iZmBJPVRO4sBYwSyPA7PF0DM6WcIQqSFoUtjU95JOjyLVoqyiY3a1mOgTkRM0VXragg6HsgFtRb7i7IzfkzIaRVclzkOlTsnYPp09sT8hMosxPrm5bzdnMd7LumoStZoeuYz+14H6Bqszmz9Xq5hJHGg37Y9I8/zVgZa2/8zU9yJzTkK06tcJm4R9/SpEupx5ppz77Tk8jlFz2Rcyd+TOzCJ57Cxx95lOyZlxsYvQg7ozAMS31qVt624kC\",\"token_type\":\"Bearer\",\"refresh_token\":\"M.C107_BAY.-CbXmpK8e49N*aldKTyw3XzDsxJ1ZmoCvrWAfkHKV!Gsrj!eKxh*o8lEaWZJIUs4GG*uoi7sggGYZ9o1rA1UadZt!pOIH8v!HZVadSNQYxH62P2o5eFECHASIv7bCxKEolPM2*M0iQPvypjw6OdutuKxQOrXnotyevwaeXM8FnA4Bt7bnyj8OgnUFu2ccn6YceV4yr*PTp!FwKeClZZl2VdrttVULky6M2s51Q1osYosWKXc3MT9gU3yS55tDkRh9yW130Gi0heuEdn7gexVeKuMhS*8zB0CM7Yi0mZx1m06bxCUlrnEy3uqNvn6myOXsM!GyunjJU7UryMsGyTTU07s$\",\"expiry\":\"2023-12-01T01:02:34.6955871+05:30\"}\n",
            "\n",
            "Option config_type.\n",
            "Type of connection\n",
            "Choose a number from below, or type in an existing string value.\n",
            "Press Enter for the default (onedrive).\n",
            "\u001b[91m 1 / OneDrive Personal or Business\n",
            "   \\ (onedrive)\n",
            "\u001b[0m\u001b[92m 2 / Root Sharepoint site\n",
            "   \\ (sharepoint)\n",
            "\u001b[0m\u001b[91m   / Sharepoint site name or URL\n",
            " 3 | E.g. mysite or https://contoso.sharepoint.com/sites/mysite\n",
            "   \\ (url)\n",
            "\u001b[0m\u001b[92m 4 / Search for a Sharepoint site\n",
            "   \\ (search)\n",
            "\u001b[0m\u001b[91m 5 / Type in driveID (advanced)\n",
            "   \\ (driveid)\n",
            "\u001b[0m\u001b[92m 6 / Type in SiteID (advanced)\n",
            "   \\ (siteid)\n",
            "\u001b[0m\u001b[91m   / Sharepoint server-relative path (advanced)\n",
            " 7 | E.g. /teams/hr\n",
            "   \\ (path)\n",
            "\u001b[0mconfig_type> 1\n",
            "\n",
            "Option config_driveid.\n",
            "Select drive you want to use\n",
            "Choose a number from below, or type in your own string value.\n",
            "Press Enter for the default (48ac816189ef8d1e).\n",
            "\u001b[91m 1 /  (personal)\n",
            "   \\ (48ac816189ef8d1e)\n",
            "\u001b[0mconfig_driveid> 1\n",
            "\n",
            "Drive OK?\n",
            "\n",
            "Found drive \"root\" of type \"personal\"\n",
            "URL: https://onedrive.live.com/?cid=48ac816189ef8d1e\n",
            "\n",
            "y) Yes (default)\n",
            "n) No\n",
            "y/n> y\n",
            "\n",
            "Configuration complete.\n",
            "Options:\n",
            "- type: onedrive\n",
            "- token: {\"access_token\":\"EwB4A8l6BAAUAOyDv0l6PcCVu89kmzvqZmkWABkAAYViudTwPAMeRPijG8DE4UrtfS8WQZTiG0YOyjraZfoPaPuO0bCe8ClndHPMUgcX1tzy1hwi4Smhg2QeiM3GrbB+XlNXzqv+koTMLFBQUWdcKvpNQtaIVDmylB3obpL676Ky13PGuPlDGotkZZ5RvM3lfEWJirvczMeiC/hOD/e/jL1sJ5Mnj1fIPNazZhiVBKYM7VmLhK+oogBsLZulTprMZeHzhGjHSMNOXNu2IpnrYdJootshVcqadZfwN4VtQVUoejaLf3AKT5q6zPvTru1xSaujIqwXjaRN6bKErh9i2sQV2F7iRfuDcYJ3jqrTFBmukRmg3mO1tLJVPDKWFn0DZgAACGUSmZu0AEreSALimt6peNLvZFDjwx5e2Sd2nDNl/qEPZR4BgIFfdiAS6jbKdkwLl2SyL9dgx0dMEUxg8OVG4eB54mjaM9Z44ETxu9Tydf78jY5j7vZct7coYDdjyOQiTIDbPHaNYIQnFSjNzfx6EUsPh55bLi0wHy3y48bBrDAfZCMrU3TZxAPBSF9FlF9yFjzcqSxqAFkWXRFVEZ54riTPYn4JRLjb/9dfUfbIuFiPZI5xC3P6piDny2vrv4bozTUAxpt1mllsXUpLRfOWGY2NThHpxqkdhIuo7CSfIWHG6vdIKK1hkh+Pd+0TVWSEXUP7ETvrn27xQG1GMNzYNvuvLBvosaDYrinPpNpOZi6ooMM8FRe90pNDeSxkexOPhXF/fHn6S0017B/Gk8t7ht4+ZPBxyVvZDR9HKidLhRHtUC+moXeK+ThQRmDcwsBbhvEBhcS1JWA0RO6GY8F0OWEpHJnSVbyuiXMFYVrWJc/ua1j6BIpXVDZ1KEPiCm6/HfeTBoGDT/+J8e4VfOvb8i8lcT5zntMVF7iZmBJPVRO4sBYwSyPA7PF0DM6WcIQqSFoUtjU95JOjyLVoqyiY3a1mOgTkRM0VXragg6HsgFtRb7i7IzfkzIaRVclzkOlTsnYPp09sT8hMosxPrm5bzdnMd7LumoStZoeuYz+14H6Bqszmz9Xq5hJHGg37Y9I8/zVgZa2/8zU9yJzTkK06tcJm4R9/SpEupx5ppz77Tk8jlFz2Rcyd+TOzCJ57Cxx95lOyZlxsYvQg7ozAMS31qVt624kC\",\"token_type\":\"Bearer\",\"refresh_token\":\"M.C107_BAY.-CbXmpK8e49N*aldKTyw3XzDsxJ1ZmoCvrWAfkHKV!Gsrj!eKxh*o8lEaWZJIUs4GG*uoi7sggGYZ9o1rA1UadZt!pOIH8v!HZVadSNQYxH62P2o5eFECHASIv7bCxKEolPM2*M0iQPvypjw6OdutuKxQOrXnotyevwaeXM8FnA4Bt7bnyj8OgnUFu2ccn6YceV4yr*PTp!FwKeClZZl2VdrttVULky6M2s51Q1osYosWKXc3MT9gU3yS55tDkRh9yW130Gi0heuEdn7gexVeKuMhS*8zB0CM7Yi0mZx1m06bxCUlrnEy3uqNvn6myOXsM!GyunjJU7UryMsGyTTU07s$\",\"expiry\":\"2023-12-01T01:02:34.6955871+05:30\"}\n",
            "- drive_id: 48ac816189ef8d1e\n",
            "- drive_type: personal\n",
            "Keep this \"onedrive\" remote?\n",
            "y) Yes this is OK (default)\n",
            "e) Edit this remote\n",
            "d) Delete this remote\n",
            "y/e/d> y\n",
            "\n",
            "Current remotes:\n",
            "\n",
            "Name                 Type\n",
            "====                 ====\n",
            "onedrive             onedrive\n",
            "\n",
            "e) Edit existing remote\n",
            "n) New remote\n",
            "d) Delete remote\n",
            "r) Rename remote\n",
            "c) Copy remote\n",
            "s) Set configuration password\n",
            "q) Quit config\n",
            "e/n/d/r/c/s/q> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo mkdir /content/onedrive\n",
        "!nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlYyPvsHgYRT",
        "outputId": "7f3877fc-5cb2-455a-f98f-20c57101d6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/llama-2-7b-codeexplainer /content/onedrive"
      ],
      "metadata": {
        "id": "mJixL8TVgeVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}